{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d3d1036",
   "metadata": {
    "id": "2d3d1036"
   },
   "source": [
    "# Introduction to Tensorflow\n",
    "\n",
    "Here we define import some useful libraries to understand the concepts behind TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22cab821",
   "metadata": {
    "id": "22cab821"
   },
   "outputs": [],
   "source": [
    "# Importing basic libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rPDn1QaGfaS7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "rPDn1QaGfaS7",
    "outputId": "675e8069-a4b4-4a13-adcc-eb9d3ea26261"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.8.0'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a16b62",
   "metadata": {
    "id": "43a16b62"
   },
   "source": [
    "## What is Tensorflow?\n",
    "Tensorflow is a free to use end-to-end platform for machine learning (ML). It is made up of a comprehensive and flexible ecosystem of tools, libraries, and community resources that enable researchers and developers to build and deploy ML-based applications.\n",
    "\n",
    "Some of the main advantages of tensorflow are:\n",
    "\n",
    "|Easy model building|Robust ML production|Experimentation for research|\n",
    "|---|---|---|\n",
    "|<img src=\"https://www.tensorflow.org/site-assets/images/marketing/home/model.svg\" width=\"80%\"> | <img src=\"https://www.tensorflow.org/site-assets/images/marketing/home/robust.svg\" width=\"80%\" />|<img src=\"https://www.tensorflow.org/site-assets/images/marketing/home/research.svg\" width=\"80%\" />|\n",
    "| It makes it easy to deploy and train <br/> ML models using high-level APIs <br/> like *Keras* with *eager execution*, which, <br/> allows for easy building and debugging.| It enables easy <br/>training and deployment of models in the cloud, on mobile devices, or <br/>in a browser regardless of the language used.| It has a simple and flexible architecture to <br/> take new ideas from concept to <br/>code, allows you to use the latest <br/>state-of-the-art models to publish faster.\n",
    "|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416f90b0",
   "metadata": {
    "id": "416f90b0"
   },
   "source": [
    "# 1. General concepts in Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388b836",
   "metadata": {
    "id": "b388b836"
   },
   "source": [
    "## Computational graph\n",
    "\n",
    "Tensorflow is very useful in *Deep learning* fundamentally because it allows automatic differentiation and parallelizes mathematical operations. Tensorflow achieves this by internally building a computational graph:\n",
    "\n",
    "<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/images/intro_to_graphs/two-layer-network.png?raw=1\" width=\"70%\" />\n",
    "\n",
    "This graph defines a data flow based on mathematical expressions. More specifically, Tensorflow uses a directed graph where each node represents an operation or variable.\n",
    "\n",
    "One of the main advantages of using a computational graph is that operations are defined as relationships or dependencies, which allows computations to be easily simplified and parallelized. This is much more practical compared to a conventional program where the operations are executed sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e8de7",
   "metadata": {
    "id": "563e8de7"
   },
   "source": [
    "## Tensors\n",
    "\n",
    "The main data structure used in Tensorflow are tensors. These are multidimensional arrays that allow information to be stored. They can be viewed as a generalization of scalars (0D-tensor), vectors (1D-tensor), and matrices (2D-tensor). Let's see some examples of tensors of different orders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30089f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b30089f8",
    "outputId": "ffc4a0ca-0998-43f3-9c4a-a395826bd64c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 3 4 5], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# we define a constant 1D-tensor (vector) from a constant list\n",
    "t = tf.constant([2, 3, 4, 5], dtype=tf.int32)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc19ba3",
   "metadata": {
    "id": "6dc19ba3"
   },
   "source": [
    "A tensor has two basic properties: \n",
    "* shape (`shape`)\n",
    "* type (`dtype`) \n",
    "\n",
    "On the one hand, the `shape`, as in `numpy`, indicates the order, number of dimensions, and the size of each dimension. In the previous example we have a tensor of order 1, that is, a single dimension, of size 4.\n",
    "On the other hand, as in any programming language, tensors have an internal representation type: `tf.int32`, `tf.float32`, `tf.string`, among others. A correct selection of the data type can make the codes more efficient. In the example above, the type of the tensor is 32-bit integer.\n",
    "\n",
    "The following example corresponds to a tensor of **order** 2, a matrix, whose **type** is a 32-bit float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd7e1ed7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd7e1ed7",
    "outputId": "6920749a-dfa6-4b68-9d5d-df5bded44eaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[9. 5.]\n",
      " [1. 0.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# we define a 2D-tensor (matrix) variable from a list\n",
    "t = tf.constant([[9, 5], [1, 0]], dtype=tf.float32)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b726f8cb",
   "metadata": {
    "id": "b726f8cb"
   },
   "source": [
    "In Tensorflow there are two main types of tensors:\n",
    "\n",
    "* ```tf.constant```: these are immutable multidimensional arrays, that is, they are tensors that will not change during execution.\n",
    "* ```tf.Variable```: these are tensors whose values can change during execution (for example, the parameters of a model are defined as variables, since these values are updated iteratively).\n",
    "\n",
    "Let's see an example of variables in tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c77246d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c77246d",
    "outputId": "ca2c4384-7ec2-46ed-cb37-0fe93ccb6d1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[1., 2.],\n",
      "       [3., 4.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# we define a 2D-tensor (matrix) variable from a list\n",
    "t = tf.Variable([[1, 2], [3, 4]], dtype=tf.float32)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32007c9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32007c9f",
    "outputId": "0e8ac466-45bd-4716-e50a-51833a4b2f8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[-2., -1.],\n",
      "       [-3., -7.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# we can assign it a new value\n",
    "t.assign([[-2, -1], [-3, -7]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ac6026",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86ac6026",
    "outputId": "ad6dc3a6-b8b8-4353-a3ba-22f699f04ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[-1.,  0.],\n",
      "       [-2., -6.]], dtype=float32)>\n",
      "<tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
      "array([[-3., -2.],\n",
      "       [-4., -8.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# or we can add or substract a value\n",
    "t.assign_add([[1, 1], [1, 1]])\n",
    "print(t)\n",
    "t.assign_sub([[2, 2], [2, 2]])\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffdf2fd",
   "metadata": {
    "id": "2ffdf2fd"
   },
   "source": [
    "We can perform various operations and define functions on tensors, likewise, tensorflow provides a similar *slicing* to that of numpy arrays. Let's look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "023f55aa",
   "metadata": {
    "id": "023f55aa"
   },
   "outputs": [],
   "source": [
    "# we define a 2D-tensor A\n",
    "A=tf.constant([[1, 2], [3, 4]], dtype=tf.float32)\n",
    "# we define a 2D-tensor B\n",
    "B=tf.constant([[-1, -2], [-3, -4]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "498577f0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "498577f0",
    "outputId": "83fa0256-533f-437a-a03e-a862aa9a0fc0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[0., 0.],\n       [0., 0.]], dtype=float32)>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum\n",
    "A + B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6406fd03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6406fd03",
    "outputId": "bfc5ee4d-bf48-4643-be17-74ef80e3bf98"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[2., 4.],\n       [6., 8.]], dtype=float32)>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# substraction\n",
    "A - B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fbb9d66",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9fbb9d66",
    "outputId": "1ec2831d-8d63-4cfc-86d7-9634ce437b59"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ 3.,  6.],\n       [ 9., 12.]], dtype=float32)>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalar multiplication (in Python)\n",
    "3 * A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6bd8275",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6bd8275",
    "outputId": "82c229d9-c09b-4344-c8cc-f0a576568971"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ -1.,  -4.],\n       [ -9., -16.]], dtype=float32)>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Element-wise multiplication\n",
    "A * B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82ee7d59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82ee7d59",
    "outputId": "0d97a5e7-3b44-48f2-9232-acc3d28495df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ -7. -10.]\n",
      " [-15. -22.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "print(tf.matmul(A, B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6398b2a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6398b2a9",
    "outputId": "f563b440-2e50-4b5b-a3b8-a185dcdabe24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      " [[1. 2.]\n",
      " [3. 4.]]\n",
      "First row:\n",
      " [1. 2.]\n",
      "First element of the first row: \n",
      " 1.0\n",
      "Second column:\n",
      " [2. 4.]\n",
      "Inverted rows:\n",
      " [[3. 4.]\n",
      " [1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "# Slicing examples\n",
    "print('Original tensor:\\n {}'.format(A))\n",
    "print('First row:\\n {}'.format(A[0]))\n",
    "print('First element of the first row: \\n {}'.format(A[0, 0]))\n",
    "print('Second column:\\n {}'.format(A[:, 1]))\n",
    "print('Inverted rows:\\n {}'.format(A[::-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90714fc1",
   "metadata": {
    "id": "90714fc1"
   },
   "source": [
    "We can also apply different mathematical functions to all elements of a tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "547a3ff1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "547a3ff1",
    "outputId": "dc350064-eb0b-44c1-9634-571b81305c4c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[0.       , 0.6931472],\n       [1.0986123, 1.3862944]], dtype=float32)>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logarithm \n",
    "tf.math.log(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a43fcc",
   "metadata": {
    "id": "51a43fcc"
   },
   "source": [
    "Other types of arithmetic operations, mathematical functions, and linear algebra operations can be found in the ```tf.math``` package and for linear algebra in the ```tf.linalg``` package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18113821",
   "metadata": {
    "id": "18113821"
   },
   "source": [
    "## Eager execution\n",
    "\n",
    "*Tensorflow* provides an imperative programming environment (*Eager execution*) to evaluate operations immediately without the need for the user to explicitly specify a graph. That is, the result of the operations are concrete values ​​instead of symbolic variables within the computational graph. In addition, it also allows the graph to be built automatically in cases where it is required. This makes it easier to get started programming in *Tensorflow* and debugging models. Additionally, *Eager execution* supports most of the features of *Tensorflow* and also allows GPU acceleration.\n",
    "\n",
    "*Eager execution* is a flexible platform for research and experimentation that provides:\n",
    "\n",
    "* **Intuitive interface**: Allows you to develop code naturally and use Python data structures. It also allows rapid development of applications in cases with small models and little data.\n",
    "\n",
    "* **Simple debugging**: executing the operations directly allows you to review the models in detail during execution and evaluate changes. In addition, it uses native Python debugging tools to report bugs immediately.\n",
    "\n",
    "* **Natural Control**: Controlling variables from Python instead of control via a graph simplifies the specification of more dynamic models.\n",
    "\n",
    "*Tensorflow* 2.0 comes with *Eager execution* by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15ee2c9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "15ee2c9e",
    "outputId": "334276bb-9327-4cbc-dd1a-760d627ca9c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'2.8.0'"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We check tf version\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a28fd075",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a28fd075",
    "lines_to_next_cell": 1,
    "outputId": "2506a54e-ffc1-4c0c-cb6e-b2b421c7f79d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We check if eager execution is active\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437d6d05",
   "metadata": {
    "id": "437d6d05"
   },
   "source": [
    "By default, *Eager execution* executes operations sequentially, that is, it does not build a computational graph unless it is necessary for some operation or specified. For tensorflow to build the graph we must use the ```tf.function``` decorator as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7f7fad2",
   "metadata": {
    "id": "c7f7fad2",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# We define a decorated function (it internally builds the computational graph)\n",
    "@tf.function\n",
    "def poly(x):\n",
    "    y1 = 2 * x + 3 * x ** 4 + 5 * x ** 2    \n",
    "    y2 = 5 * x + - 2 * x ** 4 + - 3 * x ** 2\n",
    "    y3 = x + 2\n",
    "    return  y1 + y2 + y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12d4891a",
   "metadata": {
    "id": "12d4891a",
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# We define a normal function in Python (it executes the operations sequentially)\n",
    "def poly2(x):\n",
    "    y1 = 2 * x + 3 * x ** 4 + 5 * x ** 2\n",
    "    y2 = 5 * x + - 2 * x ** 4 + - 3 * x ** 2\n",
    "    y3 = x + 2\n",
    "    return  y1 + y2 + y3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dc7e76",
   "metadata": {
    "id": "37dc7e76"
   },
   "source": [
    "Now, let's compare the average time between these two functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "047bbe29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "047bbe29",
    "outputId": "141843e8-ddb7-4e1d-ba07-f69b84bea02f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343 µs ± 106 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1000\n",
    "poly(tf.constant([1, 2, 3, 4], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "041e6a14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "041e6a14",
    "outputId": "85297c30-fc4e-4b08-b844-fa066d6f139d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "816 µs ± 103 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1000\n",
    "poly2(tf.constant([1, 2, 3, 4], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a56f66e",
   "metadata": {
    "id": "0a56f66e"
   },
   "source": [
    "## Numpy integration\n",
    "\n",
    "One of the main advantages of Tensorflow 2.0 is its support for arrays and numpy operations. The latter is the most used linear algebra library in python.\n",
    "\n",
    "Let's see some examples with numpy and Tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07bb3da6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07bb3da6",
    "outputId": "ad1db6de-e11a-41a5-98cd-99c010af9da2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We define an array in numpy, the linspace function creates a sequence of 'num' numbers\n",
    "# equally spaced between two limits 'start' and 'stop'\n",
    "x = np.linspace(start=0, stop=1, num=10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "255d9de6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "255d9de6",
    "outputId": "e1329bc9-f3ef-42d8-b477-8060c4548d04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(), dtype=float64, numpy=5.0>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We perform some operations in Tensorflow\n",
    "acum = tf.reduce_sum(x)\n",
    "acum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "419a5aca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "419a5aca",
    "outputId": "427b7b5d-ede7-410b-e7ab-ef21ae522f06"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10,), dtype=float32, numpy=\narray([0.        , 0.11111111, 0.22222222, 0.33333334, 0.44444445,\n       0.5555556 , 0.6666667 , 0.7777778 , 0.8888889 , 1.        ],\n      dtype=float32)>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We define a tensor in TensorFlow\n",
    "x = tf.linspace(0.0, 1.0, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d12725bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d12725bf",
    "outputId": "4716a975-f3a2-4be6-81bd-e24614fcdca3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "5.0"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we perform some operations in numpy\n",
    "acum = np.sum(x)\n",
    "acum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "901c55cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "901c55cb",
    "outputId": "3cb8b25a-46a6-457c-a734-8314c3c3abaa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(10,), dtype=float64, numpy=\narray([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ])>"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also convert a numpy array to a tensor\n",
    "x = np.linspace(0, 1, 10)\n",
    "t = tf.constant(x)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b16b3df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b16b3df",
    "outputId": "68369eb7-8c9d-48d7-996c-c7043e53714e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.        , 0.11111111, 0.22222222, 0.33333334, 0.44444445,\n       0.5555556 , 0.6666667 , 0.7777778 , 0.8888889 , 1.        ],\n      dtype=float32)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Also, a tensor into a numpy array\n",
    "t = tf.linspace(0.0,1.0,10)\n",
    "x = t.numpy()\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cc2141",
   "metadata": {
    "id": "07cc2141"
   },
   "source": [
    "# 2. Keras\n",
    "\n",
    "Originally, Keras was a high-level *framework* written in Python that used different *backends* of *deep learning* such as: Tensorflow, CNTK or Theano. Currently, it is a package within Tensorflow 2.0 that allows us to simplify both the training and the design of *machine learning* models and neural networks. It also includes built-in and custom layers, models, optimizers, loss functions and metrics.\n",
    "\n",
    "```tf.keras``` is used for fast model creation and has three advantages:\n",
    "\n",
    "* **User friendly**: keras has a simple and consistent interface that has been optimized for use in typical cases.\n",
    "* **Modular**: Model building is based on connecting customizable blocks with few restrictions.\n",
    "* **Easy extension**: allows you to easily implement new modules using all Tensorflow features, which makes it easy to build new models or state-of-the-art models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e3408",
   "metadata": {},
   "source": [
    "## Layers\n",
    "\n",
    "In keras, `Layers` are the basic building blocks of neural networks. A layer can be understood as a simple input-output transformation. From the point of view of TensorFlow, a layer also consists of a tensor-in tensor-out computation function  and some state, held in TensorFlow variables (**the layer's weights**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a60d0bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For instance here's a linear projection layer that maps its inputs to a 16-dimensional feature space\n",
    "dense = tf.keras.layers.Dense(units=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f58be99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also declare a layer to receive a RGB image from any size\n",
    "inputs = tf.keras.Input(shape=(None, None, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e047db",
   "metadata": {},
   "source": [
    "Almost all layers have:\n",
    "\n",
    "* Weights: They create a linear combination of the outputs that come from the previous layer.\n",
    "* Non-linear activation: It introduces non-linearities during the training process.\n",
    "* A bias node: An equivalent to one incoming variable that is always set to 1.\n",
    "\n",
    "## Most used Keras layers\n",
    "\n",
    "Here you can see some of the most used layers from Keras:\n",
    "\n",
    "|               | Data types               | Weights from last layer                    |\n",
    "|---------------|--------------------------|--------------------------------------------|\n",
    "| `InputLayer`    | All                      | None                                       |\n",
    "| `Embedding`     | Categorical, text        | Categorical input to vector                |\n",
    "| `Dense`         | All                      | Get fed to each neuron                     |\n",
    "| `Dropout`       | Most                     | Get fed to each neuron, with a probability |\n",
    "| `Convolutional` | Text, time series, image | Adjacent weights get combined              |\n",
    "| `Max Pooling`   | Text, time series, image | Take max of adjacent weights               |\n",
    "| `RNN`           | Text, time series        | Each \"timestep\" gets fed in order          |\n",
    "| `LSTM`          | Text, time series        | Each \"timestep\" gets fed in order          |\n",
    "| `Bidirectional` | Text, time series        | Get passed on both forwards and backwards  |\n",
    "\n",
    "[Table adapted from](https://www.hergertarian.com/keras-layers-intro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62784ae",
   "metadata": {},
   "source": [
    "In our next notebook, we will use some of this layers for building a small neural network"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "1_tensorflow_intro.ipynb",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "id,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "pycharm-1b5a5f60",
   "language": "python",
   "display_name": "PyCharm (se4ai-pr01-gr07)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}